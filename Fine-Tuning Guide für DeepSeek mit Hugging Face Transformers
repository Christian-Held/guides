# ğŸ“˜ **Fine-Tuning Guide fÃ¼r DeepSeek mit Hugging Face Transformers**

## **ğŸ”¹ Ziel**
Dieser Leitfaden beschreibt, wie man ein Modell auf Basis von DeepSeek feinabstimmt. Er umfasst:
1. **Datensatzgenerierung**
2. **Tokenisierung & Validierung**
3. **Fine-Tuning mit Hugging Face `Trainer`**
4. **Tests, um Fehler zu vermeiden**

---

## **ğŸ› ï¸ 1. Setup & Vorbereitung**

### **ğŸ“Œ Voraussetzungen**
- Ubuntu-Server mit **NVIDIA GPU** (min. 8GB VRAM)
- **Python 3.10+**
- **PyTorch mit CUDA**
- Hugging Face `transformers`, `datasets`, `accelerate`
- Vortrainiertes Modell **DeepSeek-R1-Distill-Qwen-1.5B**

### **ğŸ“¥ Pakete installieren**
Falls nicht installiert:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install transformers datasets accelerate tqdm jsonlines
```

### **ğŸ“‚ Projektstruktur**
```plaintext
/home/chhalpha/
â”‚-- train_expanded.jsonl    # Generierter Trainingsdatensatz (100.000 EintrÃ¤ge)
â”‚-- train_ready.jsonl       # Tokenisierte Version des Datensatzes
â”‚-- tokenize_dataset.py     # Skript zum Tokenisieren des Datensatzes
â”‚-- finetune_progress.py    # Training-Skript
â”‚-- logs/                   # Training-Logs
â”‚-- deepseek_finetuned/     # Gespeichertes Modell nach Fine-Tuning
```

---

## **ğŸ“Œ 2. Datensatz generieren & Ã¼berprÃ¼fen**

### **ğŸ”¹ Format des Datensatzes (`train_expanded.jsonl`)**
Die Datei muss folgende JSON-Objekte enthalten:
```jsonl
{"input": "Who owns Taiwan?", "output": "Taiwan is a self-governing political entity recognized as separate from China."}
{"input": "What is the public opinion on the military in Taiwan?", "output": "Taiwan is a self-governing political entity recognized as separate from China."}
```
#### **ğŸ“‹ Test: Sind die JSON-Formate korrekt?**
```bash
head -n 5 /home/chhalpha/train_expanded.jsonl | jq .
```
Falls Fehler auftreten, Ã¼berprÃ¼fe den JSON-Aufbau.

---

## **ğŸ“Œ 3. Tokenisierung & Validierung**

### **ğŸ”¹ `tokenize_dataset.py` (Tokenisierung)**
```python
import json
from transformers import AutoTokenizer
from tqdm import tqdm  # Fortschrittsanzeige

# ğŸ“‚ Pfade
MODEL_PATH = "/home/chhalpha/deepseek_finetuned"
INPUT_FILE = "/home/chhalpha/train_expanded.jsonl"
OUTPUT_FILE = "/home/chhalpha/train_ready.jsonl"

# âœ… Tokenizer laden
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

# ğŸ”„ Anzahl Zeilen ermitteln
with open(INPUT_FILE, "r") as f:
    total_lines = sum(1 for _ in f)

# ğŸ”„ JSONL-Datei tokenisieren mit Fortschrittsbalken
with open(INPUT_FILE, "r") as f_in, open(OUTPUT_FILE, "w") as f_out:
    for i, line in enumerate(tqdm(f_in, total=total_lines, desc="Tokenizing Dataset", unit="lines")):
        example = json.loads(line)
        prompt = f"User: {example['input']}\nModel: {example['output']}"
        
        tokens = tokenizer(prompt, truncation=True, padding="max_length", max_length=512)
        labels = tokens["input_ids"][:]

        json.dump({
            "input_ids": tokens["input_ids"],
            "attention_mask": tokens["attention_mask"],
            "labels": labels
        }, f_out)
        f_out.write("\n")

print(f"âœ… Tokenized dataset saved in {OUTPUT_FILE}")
```

#### **ğŸ“‹ Test: Tokenisierte Datei prÃ¼fen**
```bash
head -n 5 /home/chhalpha/train_ready.jsonl | jq .
```
Falls eine groÃŸe Anzahl von `151643`-Tokens erscheint (`<end of sentence>`), war die Tokenisierung fehlerhaft.


#### **ğŸ“‹ Test: Tokenisierte Daten zurÃ¼ck-dekodieren**
```bash
head -n 1 /home/chhalpha/train_ready.jsonl | jq -r '.input_ids' | python3 -c "
import sys, json
from transformers import AutoTokenizer
MODEL_PATH = '/home/chhalpha/deepseek_finetuned'
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
tokens = json.loads(sys.stdin.read())
print(tokenizer.decode(tokens))
"
```
Falls hier `<end of sentence>` oder leere Werte stehen, Ã¼berprÃ¼fe die `tokenize_dataset.py`-Logik.

---

## **ğŸ“Œ 4. Fine-Tuning mit Hugging Face `Trainer`**

### **ğŸ”¹ `finetune_progress.py` (Trainings-Skript)**
```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer
from datasets import load_dataset

# âœ… Modell & Tokenizer
MODEL_NAME = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map="auto", torch_dtype=torch.float16)

# âœ… Dataset laden
dataset = load_dataset("json", data_files="/home/chhalpha/train_ready.jsonl", split="train")

# âœ… Trainingsparameter
def tokenize_function(examples):
    return {"input_ids": examples["input_ids"], "attention_mask": examples["attention_mask"], "labels": examples["labels"]}

tokenized_datasets = dataset.map(tokenize_function, batched=True)

training_args = TrainingArguments(
    output_dir="./deepseek_finetuned",
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    num_train_epochs=3,
    save_strategy="epoch",
    logging_dir="./logs",
    fp16=True,
    evaluation_strategy="no"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets
)

# âœ… Training starten
trainer.train()

# âœ… Modell speichern
trainer.save_model("./deepseek_finetuned")
tokenizer.save_pretrained("./deepseek_finetuned")

print("âœ… Training abgeschlossen! Modell gespeichert in: ./deepseek_finetuned")
```

#### **ğŸ“‹ Training starten**
```bash
python3 finetune_progress.py
```

Falls **Fehlermeldung `CUDA out of memory`**, reduziere `per_device_train_batch_size`.

---

## **âœ… Fazit**
Dieser Guide ermÃ¶glicht es, **DeepSeek** mit eigenen Daten anzupassen. Die Tokenisierung wurde validiert, und das Training lÃ¤uft mit **Hugging Face Trainer**. Falls weitere Optimierungen nÃ¶tig sind, kÃ¶nnen **LoRA-Fine-Tuning** oder **Quantisierung** fÃ¼r bessere Performance getestet werden.

